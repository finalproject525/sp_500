services:
    dev_env:
        container_name: dev_env
        build:
          context: .
          dockerfile: Dockerfile.dev_env
        ports:
          - "22022:22"      # SSH
          - "8888:8888"     # Jupyter
          - "4040:4040"     # Spark UI
          - "4041:4041"
          - "4042:4042"
        volumes:
          - ../workspace:/workspace
        env_file:
          - ../.env


    minio:
        container_name: minio
        image: minio/minio:RELEASE.2022-11-08T05-27-07Z
        command: server /data --console-address ":9001"
        ports:
            - "9001:9000"
            - "9002:9001"

    zookeeper:
        container_name: zookeeper
        image: wurstmeister/zookeeper:latest
        ports:
            - "2181:2181"

    course-kafka:
        container_name: course-kafka
        image: wurstmeister/kafka:2.13-2.8.1
        environment:
            KAFKA_ADVERTISED_HOST_NAME: course-kafka
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
        ports:
            - "9092:9092"
        depends_on:
            - zookeeper

    kafdrop:
        container_name: kafdrop
        image: obsidiandynamics/kafdrop:3.30.0
        ports:
            - "9003:9000"
        environment:
            - KAFKA_BROKERCONNECT=course-kafka:9092
        depends_on:
            - course-kafka

    mongo:
        image: nayacollege/mongo:1.0
        container_name: mongo
        ports:
            - "27017:27017"
                                    
      postgres:
        container_name: postgres
        image: postgres:15
        environment:
          - POSTGRES_USER=postgres
          - POSTGRES_PASSWORD=postgres
          - POSTGRES_DB=airflow
        ports:
          - "5432:5432"

      airflow-init:
        image: apache/airflow:2.8.1
        container_name: airflow_init
        depends_on:
          - postgres
        environment:
          - AIRFLOW__CORE__EXECUTOR=LocalExecutor
          - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
          - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
          - AIRFLOW__CORE__LOAD_EXAMPLES=False
          - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
        volumes:
          - ../workspace/sp500/dags:/opt/airflow/dags
        entrypoint: /bin/bash
        command:
          - -c
          - >
            airflow users list || (
              airflow db init &&
              airflow users create
                --role Admin
                --username airflow
                --password airflow
                --email airflow@airflow.com
                --firstname airflow
                --lastname airflow
            )
        restart: on-failure

      airflow-webserver:
        image: apache/airflow:2.8.1
        container_name: airflow_webserver
        depends_on:
          - postgres
        environment:
          - AIRFLOW__CORE__EXECUTOR=LocalExecutor
          - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
          - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
          - AIRFLOW__CORE__LOAD_EXAMPLES=False
          - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
        volumes:
          - ../workspace/sp500/dags:/opt/airflow/dags
        ports:
          - "8082:8080"
        command: airflow webserver
        restart: always

      airflow-scheduler:
        image: apache/airflow:2.8.1
        container_name: airflow_scheduler
        depends_on:
          - postgres
        environment:
          - AIRFLOW__CORE__EXECUTOR=LocalExecutor
          - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
          - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
          - AIRFLOW__CORE__LOAD_EXAMPLES=False
          - AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
        volumes:
          - ../workspace/sp500/dags:/opt/airflow/dags
        command: airflow scheduler
        restart: always